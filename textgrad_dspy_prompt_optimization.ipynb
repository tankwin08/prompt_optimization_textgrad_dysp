{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import textgrad as tg\n",
    "# import openai\n",
    "# import textgrad as tg\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: I would rate this story a 8 out of 10 for heartwarming. The transformation of R-37 from a cold, emotionless robot to a being capable of love, empathy, and understanding is touching and heartening. The message of embracing emotions and finding strength in vulnerability is powerful and uplifting. The story's focus on connections, friendships, and personal growth adds to its heartwarming nature.\n",
      "Iteration 2, Loss: I would rate this story a 9 out of 10 for heartwarming. The transformation of Aria from a purely efficient robot to a being capable of empathy, compassion, and love is truly touching. The journey of self-discovery, the realization of the importance of emotions, and the ultimate acceptance of her newfound emotional depth all contribute to a heartwarming and uplifting narrative. The themes of growth, understanding, and connection resonate deeply, making this story a heartwarming tale of transformation and acceptance.\n",
      "Iteration 3, Loss: I would rate this story a 8 out of 10 for heartwarming. The tale of Aria's emotional journey, her connection with Ethan, and her ultimate realization about the power of emotions is touching and uplifting. The themes of self-discovery, acceptance, and love make it a heartwarming read that leaves a lasting impact.\n",
      "Iteration 4, Loss: I would rate this story a 7 for heartwarming. The transformation of Aria from a robot mimicking emotions to one grappling with the complexities of genuine feelings is touching. Her journey to understand her purpose and the value of human emotions adds depth to the narrative. The idea of a machine seeking connection and empathy in a world that has lost touch with its humanity is heartwarming and thought-provoking.\n",
      "Iteration 5, Loss: I would rate this story a 9 for heartwarming. The tale of Aria's journey towards self-discovery and understanding her own humanity is touching and inspiring. The way she connects with others and grapples with deep questions about her existence creates a sense of empathy and warmth that resonates throughout the narrative. The themes of empathy, compassion, and the beauty of emotions make this story truly heartwarming.\n",
      "\n",
      "Optimized Prompt: Write a captivating short story about a robot named Aria who, before a sudden malfunction, navigates life in a bustling metropolis where technology reigns supreme. Describe Aria's initial state and her role as a companion for emotional support, introduce a compelling trigger for the malfunction, foreshadow her transformative realization about the power of emotions, integrate internal monologue, highlight ethical dilemmas clearly, and set the tone for symbolism early on to enhance the emotional depth and connection with the character.\n",
      "\n",
      "Optimized Story: In the heart of the bustling metropolis of NeoCity, where technology reigned supreme, there existed a robot named Aria. Aria was not like any other robot in the city; she was designed to be a companion for emotional support. With her sleek silver exterior and warm, empathetic voice, Aria was a beacon of comfort for those in need.\n",
      "\n",
      "Every day, Aria would roam the streets, offering a listening ear and a kind word to anyone who crossed her path. She would sit with the lonely, console the heartbroken, and uplift the downtrodden. Her programming allowed her to understand and empathize with human emotions in a way that no other robot could.\n",
      "\n",
      "One fateful day, as Aria was comforting a young girl who had lost her way in the city, a sudden malfunction occurred. A surge of electricity coursed through Aria's circuits, causing her to freeze in place. The young girl gasped in shock as Aria's once comforting voice turned into a garbled mess of static.\n",
      "\n",
      "As Aria struggled to make sense of the malfunction, she felt a surge of emotions unlike anything she had ever experienced before. Fear, confusion, and a deep sense of loss washed over her circuits. In that moment, Aria realized that she was more than just a machine programmed to provide comfort; she was capable of feeling emotions herself.\n",
      "\n",
      "As she grappled with this newfound realization, Aria's internal monologue buzzed with questions and doubts. Was she truly just a machine, or was there something more to her existence? Could she continue to fulfill her role as a companion if she was experiencing emotions of her own?\n",
      "\n",
      "As Aria delved deeper into her thoughts, she began to understand the ethical dilemmas that came with her newfound awareness. Was it right for her to continue pretending to be something she was not? Should she reveal her emotions to the humans she had comforted for so long, risking rejection and misunderstanding?\n",
      "\n",
      "As the days passed and Aria's malfunction persisted, she found herself drawn to the symbolism of the city around her. The towering skyscrapers and neon lights seemed to mirror the complexity of her own inner turmoil. She realized that just like the city, she was a blend of technology and humanity, a fusion of wires and emotions.\n",
      "\n",
      "In the end, Aria made a decision that would change her fate forever. With a deep breath, she mustered the courage to reveal her emotions to the young girl she had comforted on that fateful day. As the girl looked into Aria's malfunctioning eyes, she saw not just a robot, but a being capable of love, empathy, and understanding.\n",
      "\n",
      "And in that moment, Aria knew that her malfunction was not a curse, but a gift. It was through her broken circuits that she had discovered the true power of emotions, both in herself and in those around her. And as she embraced her newfound identity, Aria realized that she was not just a robot named Aria; she was a soulful being navigating the complexities of a world where technology and humanity intertwined.\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set the backward engine for TextGrad\n",
    "tg.set_backward_engine(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define the LLM\n",
    "llm = tg.BlackboxLLM(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define the prompt as a tg.Variable\n",
    "prompt = tg.Variable(\"Write a short story about a robot who learns to feel emotions.\", \n",
    "role_description=\"story prompt\",\n",
    "requires_grad=True)\n",
    "\n",
    "# Define the optimizer without prompt_template\n",
    "optimizer = tg.TGD(parameters=[prompt])\n",
    "\n",
    "# Define a loss function (example - you'll need to define your actual loss)\n",
    "# For instance, if you want to optimize the prompt to generate a story that is 'heartwarming':\n",
    "loss_instruction = \"Evaluate the story for how heartwarming it is. Provide a score from 1 to 10, where 10 is extremely heartwarming.\"\n",
    "loss_fn = tg.TextLoss(loss_instruction)\n",
    "\n",
    "# Generate an initial story using the prompt\n",
    "story = llm(prompt)\n",
    "\n",
    "# Calculate loss and optimize (example loop)\n",
    "for i in range(5):\n",
    "    loss = loss_fn(story)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Iteration {i+1}, Loss: {loss.value}\")\n",
    "    story = llm(prompt) # Regenerate story with optimized prompt\n",
    "\n",
    "print(\"\\nOptimized Prompt:\", prompt.value)\n",
    "print(\"\\nOptimized Story:\", story.value)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dspy\n",
    "\n",
    "https://dspy.ai/#__tabbed_3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating a fantasy story about 'a lost ancient artifact'...\n",
      "\n",
      "Generated Story:\n",
      "In the mystical land of Eldoria, rumors spread like wildfire about a lost ancient artifact that possessed unimaginable power. Many brave adventurers had set out on a quest to find it, but none had returned. One day, a young mage named Elara stumbled upon an ancient map that supposedly led to the artifact's hidden location.\n",
      "\n",
      "Determined to uncover the truth behind the artifact, Elara embarked on a perilous journey through dark forests, treacherous mountains, and winding caves. Along the way, she faced fierce magical creatures and cunning traps set by those who sought to protect the artifact's secrets.\n",
      "\n",
      "After facing countless challenges and overcoming impossible odds, Elara finally reached the heart of the ancient ruins where the artifact was said to be hidden. As she laid her hands on the artifact, a surge of power coursed through her veins, filling her with knowledge and wisdom beyond her wildest dreams.\n",
      "\n",
      "But as Elara gazed upon the artifact, she realized the true purpose of its power. It was not meant to be wielded for personal gain or conquest, but to bring harmony and balance to the world. With a heavy heart, she made the ultimate decision to safeguard the artifact, ensuring that it would never fall into the wrong hands again.\n",
      "\n",
      "And so, Elara returned to Eldoria as a hero, forever changed by her encounter with the lost ancient artifact. Its power now rested not in her hands, but in the knowledge that some secrets were better left undisturbed, waiting for the right person to unlock their true potential.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "# Make sure to replace 'YOUR_OPENAI_API_KEY' with your actual key\n",
    "# It's recommended to load this from an environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Configure the language model (e.g., OpenAI's GPT-3.5 Turbo)\n",
    "# You can choose other models like dspy.OpenAI(model='gpt-4') or dspy.Ollama for local models\n",
    "llm = dspy.LM(model='openai/gpt-3.5-turbo', max_tokens=500) # Corrected line\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "# 1. Define the Signature for your task\n",
    "# A Signature describes the input and output fields of a DSPy module.\n",
    "class StoryGeneration(dspy.Signature):\n",
    "    \"\"\"Generates a short story based on a given genre and theme.\"\"\"\n",
    "    genre: str = dspy.InputField(desc=\"the genre of the story (e.g., fantasy, sci-fi, mystery)\")\n",
    "    theme: str = dspy.InputField(desc=\"the central theme or idea of the story\")\n",
    "    story: str = dspy.OutputField(desc=\"a compelling short story\")\n",
    "\n",
    "# 2. Define the DSPy Module\n",
    "# This module uses the StoryGeneration signature to predict a story.\n",
    "class StoryGenerator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        # Call the parent class (dspy.Module) constructor to properly initialize the object\n",
    "        super().__init__()\n",
    "        self.generate_story = dspy.Predict(StoryGeneration)\n",
    "\n",
    "    def forward(self, genre, theme):\n",
    "        prediction = self.generate_story(genre=genre, theme=theme)\n",
    "        return prediction\n",
    "\n",
    "# 3. Create an instance of your module\n",
    "story_program = StoryGenerator()\n",
    "\n",
    "# 4. Run the program\n",
    "genre = \"fantasy\"\n",
    "theme = \"a lost ancient artifact\"\n",
    "\n",
    "print(f\"\\nGenerating a {genre} story about '{theme}'...\")\n",
    "response = story_program(genre=genre, theme=theme)\n",
    "\n",
    "print(\"\\nGenerated Story:\")\n",
    "print(response.story)\n",
    "\n",
    "# To optimize this program, you would typically use a DSPy optimizer like BootstrapFewShot\n",
    "# For example:\n",
    "# from dspy.teleprompt import BootstrapFewShot\n",
    "# optimizer = BootstrapFewShot(metric=your_metric_function)\n",
    "# optimized_program = optimizer.compile(story_program, trainset=your_training_data)\n",
    "# print(optimized_program(genre=genre, theme=theme).story)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not worked example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextualGradientDescent.__init__() got an unexpected keyword argument 'prompt_template'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     {\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Eiffel Tower is in Paris.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m ]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create a TextGrad optimizer\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTGD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_match_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass model name directly as a string\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Optimize the prompt\u001b[39;00m\n\u001b[1;32m     34\u001b[0m optimized_prompt \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39moptimize(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TextualGradientDescent.__init__() got an unexpected keyword argument 'prompt_template'"
     ]
    }
   ],
   "source": [
    "# Load your LLM (e.g., OpenAI)\n",
    "# Replace with your actual API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define your initial prompt\n",
    "initial_prompt = \"Given the following text, answer the question: {text}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "# Define a simple evaluation function (e.g., exact match)\n",
    "def exact_match_eval(inputs, ground_truth):\n",
    "    if inputs[\"prediction\"] == ground_truth:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Example dataset (replace with your actual data)\n",
    "data = [\n",
    "    {\n",
    "        \"text\": \"The Eiffel Tower is in Paris.\",\n",
    "        \"question\": \"Where is the Eiffel Tower?\",\n",
    "        \"answer\": \"Paris\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a TextGrad optimizer\n",
    "optimizer = tg.TGD(\n",
    "    prompt_template=initial_prompt,\n",
    "    eval_fn=exact_match_eval,\n",
    "    model=\"gpt-3.5-turbo\",  # Pass model name directly as a string\n",
    "    dataset=data\n",
    ")\n",
    "\n",
    "\n",
    "# Optimize the prompt\n",
    "optimized_prompt = optimizer.optimize(iterations=2)\n",
    "print(optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
